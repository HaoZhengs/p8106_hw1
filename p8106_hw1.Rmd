---
title: "p8106_hw1"
author: "Hao Zheng"
date: "2/20/2022"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ISLR)
library(glmnet)
library(caret)
library(corrplot)
library(plotmo)
library(pls)
library(doBy)
```

```{r}
# Data import
train = read.csv("./data/housing_training.csv") %>% janitor::clean_names()
test = read.csv("./data/housing_test.csv") %>% janitor::clean_names()

train = na.omit(train)
test = na.omit(test)

x_train = model.matrix(sale_price~., train)[,-1]
y_train = train$sale_price

x_test <- model.matrix(sale_price~., test)[ ,-1]
y_test <- test$sale_price
```

Now, let's fit different models based on the dataset.

## Linear model
```{r}
set.seed(2022)

lm.fit = lm(sale_price ~ .,
            data = train,
            method = "lm",
            trControl = trainControl(method = "repeatedcv", number = 10))
summary(lm.fit)

pred.lm <- predict(lm.fit, newdata = test)
lm_mse = RMSE(pred.lm, test$sale_price); lm_mse
```

The test MSE for the least square method is `r lm_mse`.
Potential disadvantage of the linear model: 1. There may be too many predictors, which could cause problems such as corlinearity among predictors, large variance; 2. The model is too complex and there exist over-fitting problems.


## Lasso model
### using glmnet
```{r}
set.seed(2022)

lasso.fit <- cv.glmnet(
  x = x_train,
  y = y_train,
  alpha = 1,
  lambda = exp(seq(8, 3, length = 100))
)

plot(lasso.fit)
plot_glmnet(lasso.fit$glmnet.fit)

# Look at the 1SE coefficient for lasso
predict(lasso.fit, s = "lambda.1se",type = "coefficients")
```

When the 1SE rule is applied, we can see there are 35 predictors included in the model.

```{r}
y_pred <- predict(lasso.fit, newx = x_test, s = "lambda.min", type = "response")
lasso_mse <- mean(RMSE(y_pred, y_test)^2); lasso_mse
```

The test MSE for Lasso model (1SE) is `r lasso_mse`.


## Elastic Net model
```{r}
set.seed(2022)

enet.fit = train(x_train, y_train,
                 method = "glmnet",
                 tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                        lambda = exp(seq(8, -3, length = 50))),
                 trControl = trainControl(method = "cv", number = 10))

enet.fit$bestTune
```

The selected tuning parameter lambda = `r enet.fit$bestTune$lambda`, alpha = `r enet.fit$bestTune$alpha`. Then we visualize the elastic net result.

```{r}
# Visualization
myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(enet.fit, par.settings = myPar)

coef(enet.fit$finalModel, enet.fit$bestTune$lambda)
```

Next, we calculate the test MSE on our test dataset.
```{r}
# Elastic net test MSE
enet_pred <- predict(enet.fit, newdata = x_test)
enet_mse <- mean(RMSE(enet_pred, y_test)^2); enet_mse
```

The test error for Elastics net model is `r enet_mse`.


## Partial Least Square model
```{r}
set.seed(2022)

pls.fit <- plsr(sale_price~., 
                data = train, 
                scale = TRUE,  
                validation = "CV")

summary(pls.fit)

validationplot(pls.fit, val.type="MSEP", legendpos = "topright")
```

```{r}
# Calculate the number of component in the model
cv.mse <- RMSEP(pls.fit)
ncomp.cv <- which.min(cv.mse$val[1,,]) - 1; ncomp.cv

pls_pred <- predict(pls.fit, newdata = x_test, ncomp = ncomp.cv)
pls_mse <- mean(RMSE(y_test, pls_pred)^2); pls_mse
```

There are `r ncomp.cv` component in pls model, and the test error (MSE) is `r pls_mse`.


## Comparing different models
```{r}
name <- c("lm", "lasso 1se", "elastic net", "pls")
MSE <- c(lm_mse, lasso_mse, enet_mse, pls_mse)
comparison <- cbind(name, MSE)
comparison <- as.data.frame(comparison)
```

Now, let's compare the test MSE of the above 4 models, as we have mentioned before, linear model may have many disadvantages, so here though he test MSE for linear model is the lowest, we may tend to choose other models. Therefore, we may choose the model with the lowest MSE besides the linear model: elastic net model.
